{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ef3191-5e45-489b-81c4-cfde8f234b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "#import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b2a82-bbd0-45bd-b5a6-c8a2f12f6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 44100\n",
    "sd.default.samplerate = SR\n",
    "#sd.default.channels = 2\n",
    "#sd.default.device = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ccfd1-b2d9-4cfd-a967-da72aa25587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 5\n",
    "myrecording = sd.rec(int(duration * SR), channels=2)\n",
    "sd.wait()\n",
    "write(f'output.wav', SR, myrecording)  # Save as WAV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bfe2c-749b-48cd-8719-1c71246a23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 5\n",
    "for i in range(0, 18):\n",
    "    print(\"trying\", i)\n",
    "    sd.default.device = i\n",
    "    myrecording = sd.rec(int(duration * SR), channels=2)\n",
    "    sd.wait()\n",
    "    write(f'output{i}.wav', SR, myrecording)  # Save as WAV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe6e9e-52e3-4201-95bf-8dee8f2ce0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "myrecording\n",
    "write('output.wav', SR, myrecording)  # Save as WAV file \n",
    "myrecording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def03bd-8fa5-4ee6-a87d-a78cf8fcf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.query_devices()\n",
    "sd.query_hostapis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d374a1d-2c3b-4a52-9327-a90c4f4f39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "chunk = 1024  # Record in chunks of 1024 samples\n",
    "sample_format = pyaudio.paInt16  # 16 bits per sample\n",
    "channels = 1\n",
    "fs = 44100  # Record at 44100 samples per second\n",
    "seconds = 5\n",
    "filename = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "print('Recording')\n",
    "\n",
    "stream = p.open(format=sample_format,\n",
    "                channels=channels,\n",
    "                rate=fs,\n",
    "                frames_per_buffer=chunk,\n",
    "                input_device_index=2,\n",
    "                input=True)\n",
    "\n",
    "frames = []  # Initialize array to store frames\n",
    "\n",
    "# Store data in chunks for 3 seconds\n",
    "for i in range(0, int(fs / chunk * seconds)):\n",
    "    data = stream.read(chunk, exception_on_overflow = False)\n",
    "    frames.append(data)\n",
    "\n",
    "# Stop and close the stream \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "# Terminate the PortAudio interface\n",
    "p.terminate()\n",
    "\n",
    "print('Finished recording')\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(filename, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "wf.setframerate(fs)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaffe44b-5937-4bad-84e4-a8c1feff67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_default_input_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367638e-5bef-47d7-8e35-9e38899ffcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_device_info_by_index(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "known-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common.py\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "\n",
    "MID_TO_NAME_PATH = DATA_DIR / \"mid_to_display_name.tsv\"\n",
    "GOOGLE_AUDIO_DATASETS = [DATA_DIR / x for x in (\"audioset_eval_strong.tsv\", \"audioset_train_strong.tsv\")]\n",
    "\n",
    "AUDIO_DIR = DATA_DIR / \"audio\"\n",
    "IMAGE_DIR = DATA_DIR / \"image\"\n",
    "CHAINSAW_AUDIO_DIR = AUDIO_DIR / \"chainsaw\"\n",
    "SPEC_DIR = IMAGE_DIR / \"spectrogram\"\n",
    "MEL_SPEC_DIR = IMAGE_DIR / \"melspectrogram\"\n",
    "\n",
    "NAMES = [\"Wild animals\", \"Chainsaw\", \"Wind\", \"Rain\", \"Thunderstorm\"]\n",
    "LABEL_TO_NAME_DF = pd.read_csv(MID_TO_NAME_PATH, sep=\"\\t\", names=[\"label\", \"name\"])\n",
    "\n",
    "\n",
    "IMG_HEIGHT = IMG_WIDTH = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5209ab48-24ef-430d-850a-80ab36ab6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"melspec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7501f91b-7480-4dde-a4ff-b3bdb158c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_melspectrogram_image(signal, fname=None):\n",
    "    # create melspectrogram\n",
    "    fig, ax = plt.subplots(figsize=(0.72, 0.72))\n",
    "    if fname is None:\n",
    "        _, fname = tempfile.mkstemp(suffix=\".jpg\")\n",
    "    librosa.display.specshow(librosa.power_to_db(librosa.feature.melspectrogram(signal), ref=np.max))\n",
    "    ax.axis(\"off\")\n",
    "    fig.savefig(fname, dpi=400, bbox_inches=\"tight\", pad_inches=0)\n",
    "    fig.clear()\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "modified-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Recorder\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "audio=pyaudio.PyAudio()\n",
    "stream=audio.open(format=pyaudio.paInt16,channels=1,rate=44100,input=True,frames_per_buffer=1024)\n",
    "\n",
    "frames=[]\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        data=stream.read(1024)\n",
    "        frames.append(data)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "sound_file=wave.open(\"data/test.wav\",\"wb\")\n",
    "sound_file.setnchannels(1)\n",
    "sound_file.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "sound_file.setframerate(44100)\n",
    "sound_file.writeframes(b''.join(frames))\n",
    "sound_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d32b9ba-27d2-4d13-ac52-19a9730d2244",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f7b81b0ddfd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m\"test.wav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignal_to_melspectrogram_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "audio = librosa.load(DATA_DIR/\"test.wav\", offset=2, duration=3)[0]\n",
    "fname = signal_to_melspectrogram_image(audio)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3578b4c-dc69-4bf7-9779-1561c582c8c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to Others with a 73.11 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "img = keras.preprocessing.image.load_img(fname, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "# rescale to range [0, 1]\n",
    "img_array = keras.preprocessing.image.img_to_array(img) / 255\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "class_names = [\"Chainsaw\", \"Others\"]\n",
    "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "\n",
    "os.remove(\"data/test.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
